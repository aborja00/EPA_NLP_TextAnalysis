This project was completed as part of the "Practical Python for News Investigations" course at the CUNY Graduate School of Journalism. The assignment involved using text analysis to extract text or tables from multiple PDFs or other documents in order to quantify occurrences, search for names (such as individuals or companies), or analyze entities.

For this assignment, I focused on new  NPL (National Priorities List) sites and newly designated NPL sites available on the EPA website. I downloaded all the PDFs from the site and converted them into a text file, where I used regex to extract information such as tribe names. There are five new/prosed sites as of December 2024.

The code faced challenges due to inconsistencies in the PDFs, which often stored the same data in three different formats. Despite this, the data revealed that the new NLP site was impacting The Spokane Tribe of Indians. The tribe expressed support for the NPL listing, citing the negative effects of the Superfund site. By enabling searches across multiple PDFs, the process of locating key details in the documents became significantly faster
